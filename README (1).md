# Task-02: Image Generation with Pre-trained Models

## ğŸ“Œ Objective
The objective of this task is to generate images from text prompts using a **pre-trained generative AI model** without training a model from scratch.

---

## ğŸ§  Description
In this task, a **pre-trained Stable Diffusion model** is used to convert text descriptions into images.  
The model has already been trained on a large dataset of images and text, so it can understand natural language prompts and generate corresponding images.

The program takes a text prompt as input and produces an AI-generated image as output.

---

## ğŸ›  Tools & Technologies Used
- Python  
- Stable Diffusion (Pre-trained Model)  
- Hugging Face Diffusers  
- Google Colab  

---

## ğŸ“‚ Files in this Repository
- `task02_image_generation.py` â€“ Python program for image generation  
- `task02_output_image.png` â€“ Generated image output  
- `README.md` â€“ Task description and instructions  

---

## â–¶ï¸ How to Run the Program
1. Open **Google Colab**
2. Install required libraries:
   ```bash
   pip install diffusers transformers torch accelerate
